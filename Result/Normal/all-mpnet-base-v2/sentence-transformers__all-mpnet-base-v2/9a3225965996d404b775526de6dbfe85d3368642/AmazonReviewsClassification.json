{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 81.02543091773987,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.31442000000000003,
        "f1": 0.309708162457415,
        "f1_weighted": 0.309708162457415,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31442000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.3304,
            "f1": 0.32830126880180494,
            "f1_weighted": 0.32830126880180494
          },
          {
            "accuracy": 0.3412,
            "f1": 0.3350247577148763,
            "f1_weighted": 0.33502475771487633
          },
          {
            "accuracy": 0.3032,
            "f1": 0.2985565910366999,
            "f1_weighted": 0.2985565910366999
          },
          {
            "accuracy": 0.3192,
            "f1": 0.3199974465752723,
            "f1_weighted": 0.31999744657527224
          },
          {
            "accuracy": 0.3108,
            "f1": 0.30061774583859846,
            "f1_weighted": 0.30061774583859846
          },
          {
            "accuracy": 0.3146,
            "f1": 0.3069434844244713,
            "f1_weighted": 0.3069434844244712
          },
          {
            "accuracy": 0.2844,
            "f1": 0.2845280201659097,
            "f1_weighted": 0.2845280201659097
          },
          {
            "accuracy": 0.3132,
            "f1": 0.3132173631743479,
            "f1_weighted": 0.3132173631743479
          },
          {
            "accuracy": 0.2928,
            "f1": 0.2870811233367189,
            "f1_weighted": 0.28708112333671887
          },
          {
            "accuracy": 0.3344,
            "f1": 0.32281382350544996,
            "f1_weighted": 0.32281382350545
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30884,
        "f1": 0.3050111255332193,
        "f1_weighted": 0.30501112553321924,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30884,
        "scores_per_experiment": [
          {
            "accuracy": 0.327,
            "f1": 0.32761401440634835,
            "f1_weighted": 0.32761401440634835
          },
          {
            "accuracy": 0.342,
            "f1": 0.3352464197615333,
            "f1_weighted": 0.3352464197615333
          },
          {
            "accuracy": 0.301,
            "f1": 0.29848831183468166,
            "f1_weighted": 0.29848831183468166
          },
          {
            "accuracy": 0.3028,
            "f1": 0.3032497686504721,
            "f1_weighted": 0.30324976865047204
          },
          {
            "accuracy": 0.302,
            "f1": 0.29371971146161036,
            "f1_weighted": 0.2937197114616103
          },
          {
            "accuracy": 0.311,
            "f1": 0.30465939497487754,
            "f1_weighted": 0.3046593949748776
          },
          {
            "accuracy": 0.287,
            "f1": 0.2884493528262975,
            "f1_weighted": 0.28844935282629747
          },
          {
            "accuracy": 0.3046,
            "f1": 0.3038950409361497,
            "f1_weighted": 0.3038950409361497
          },
          {
            "accuracy": 0.2958,
            "f1": 0.291499011792426,
            "f1_weighted": 0.29149901179242604
          },
          {
            "accuracy": 0.3152,
            "f1": 0.3032902286877963,
            "f1_weighted": 0.3032902286877963
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}