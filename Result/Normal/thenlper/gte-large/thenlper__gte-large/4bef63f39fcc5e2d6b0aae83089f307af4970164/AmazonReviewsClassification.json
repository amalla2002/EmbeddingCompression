{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 68.70836281776428,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.51058,
        "f1": 0.49664553320672045,
        "f1_weighted": 0.49664553320672045,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.51058,
        "scores_per_experiment": [
          {
            "accuracy": 0.5162,
            "f1": 0.4995720447998749,
            "f1_weighted": 0.4995720447998749
          },
          {
            "accuracy": 0.5082,
            "f1": 0.4921482864344874,
            "f1_weighted": 0.49214828643448744
          },
          {
            "accuracy": 0.5106,
            "f1": 0.5022679362246183,
            "f1_weighted": 0.5022679362246183
          },
          {
            "accuracy": 0.516,
            "f1": 0.5114580624179723,
            "f1_weighted": 0.5114580624179723
          },
          {
            "accuracy": 0.5198,
            "f1": 0.49203817451046933,
            "f1_weighted": 0.49203817451046933
          },
          {
            "accuracy": 0.5236,
            "f1": 0.5137666424889039,
            "f1_weighted": 0.5137666424889039
          },
          {
            "accuracy": 0.4924,
            "f1": 0.4852914552516525,
            "f1_weighted": 0.4852914552516524
          },
          {
            "accuracy": 0.5346,
            "f1": 0.5289194228578425,
            "f1_weighted": 0.5289194228578427
          },
          {
            "accuracy": 0.5042,
            "f1": 0.48777763325299606,
            "f1_weighted": 0.4877776332529961
          },
          {
            "accuracy": 0.4802,
            "f1": 0.45321567382838807,
            "f1_weighted": 0.45321567382838823
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5075799999999999,
        "f1": 0.4940983907019585,
        "f1_weighted": 0.4940983907019585,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5075799999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.5096,
            "f1": 0.49724194068978295,
            "f1_weighted": 0.49724194068978306
          },
          {
            "accuracy": 0.5024,
            "f1": 0.4858915036927379,
            "f1_weighted": 0.4858915036927379
          },
          {
            "accuracy": 0.5072,
            "f1": 0.5006309162262,
            "f1_weighted": 0.5006309162262
          },
          {
            "accuracy": 0.5156,
            "f1": 0.5120711914707107,
            "f1_weighted": 0.5120711914707107
          },
          {
            "accuracy": 0.5048,
            "f1": 0.47426959828280896,
            "f1_weighted": 0.47426959828280896
          },
          {
            "accuracy": 0.5262,
            "f1": 0.516950884956579,
            "f1_weighted": 0.5169508849565791
          },
          {
            "accuracy": 0.4896,
            "f1": 0.48114096974955595,
            "f1_weighted": 0.481140969749556
          },
          {
            "accuracy": 0.5288,
            "f1": 0.5236564085016691,
            "f1_weighted": 0.5236564085016691
          },
          {
            "accuracy": 0.5082,
            "f1": 0.4904073662220777,
            "f1_weighted": 0.4904073662220777
          },
          {
            "accuracy": 0.4834,
            "f1": 0.45872312722746217,
            "f1_weighted": 0.45872312722746217
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}