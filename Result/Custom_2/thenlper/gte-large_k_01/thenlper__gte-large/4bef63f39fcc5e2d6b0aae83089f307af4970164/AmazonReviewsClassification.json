{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 182.21849870681763,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.51022,
        "f1": 0.4955921747144325,
        "f1_weighted": 0.4955921747144325,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.51022,
        "scores_per_experiment": [
          {
            "accuracy": 0.513,
            "f1": 0.4973141041148123,
            "f1_weighted": 0.4973141041148123
          },
          {
            "accuracy": 0.5072,
            "f1": 0.4908111112784897,
            "f1_weighted": 0.4908111112784897
          },
          {
            "accuracy": 0.5078,
            "f1": 0.49682648743064195,
            "f1_weighted": 0.496826487430642
          },
          {
            "accuracy": 0.5162,
            "f1": 0.5107742195521378,
            "f1_weighted": 0.5107742195521378
          },
          {
            "accuracy": 0.5182,
            "f1": 0.4902254737342333,
            "f1_weighted": 0.4902254737342333
          },
          {
            "accuracy": 0.522,
            "f1": 0.5126931610381515,
            "f1_weighted": 0.5126931610381517
          },
          {
            "accuracy": 0.4932,
            "f1": 0.48694729706645035,
            "f1_weighted": 0.4869472970664504
          },
          {
            "accuracy": 0.536,
            "f1": 0.5300217484869858,
            "f1_weighted": 0.5300217484869858
          },
          {
            "accuracy": 0.5076,
            "f1": 0.48758606483306116,
            "f1_weighted": 0.4875860648330612
          },
          {
            "accuracy": 0.481,
            "f1": 0.45272207960936184,
            "f1_weighted": 0.45272207960936184
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5078600000000001,
        "f1": 0.4941101811970734,
        "f1_weighted": 0.4941101811970734,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5078600000000001,
        "scores_per_experiment": [
          {
            "accuracy": 0.5082,
            "f1": 0.49714056127836626,
            "f1_weighted": 0.4971405612783662
          },
          {
            "accuracy": 0.504,
            "f1": 0.48759745160085755,
            "f1_weighted": 0.4875974516008575
          },
          {
            "accuracy": 0.5102,
            "f1": 0.5016275690827877,
            "f1_weighted": 0.5016275690827876
          },
          {
            "accuracy": 0.516,
            "f1": 0.5116407680994782,
            "f1_weighted": 0.5116407680994782
          },
          {
            "accuracy": 0.502,
            "f1": 0.47106915585601594,
            "f1_weighted": 0.471069155856016
          },
          {
            "accuracy": 0.5204,
            "f1": 0.5114570072643326,
            "f1_weighted": 0.5114570072643327
          },
          {
            "accuracy": 0.4922,
            "f1": 0.4849212727344798,
            "f1_weighted": 0.48492127273447977
          },
          {
            "accuracy": 0.5306,
            "f1": 0.525865388269559,
            "f1_weighted": 0.525865388269559
          },
          {
            "accuracy": 0.5106,
            "f1": 0.4909296109923661,
            "f1_weighted": 0.4909296109923661
          },
          {
            "accuracy": 0.4844,
            "f1": 0.45885302679249024,
            "f1_weighted": 0.4588530267924902
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}