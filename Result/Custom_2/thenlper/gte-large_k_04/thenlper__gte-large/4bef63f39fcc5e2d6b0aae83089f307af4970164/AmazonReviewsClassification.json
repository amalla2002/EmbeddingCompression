{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 182.0992295742035,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.51128,
        "f1": 0.4957326997299255,
        "f1_weighted": 0.49573269972992556,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.51128,
        "scores_per_experiment": [
          {
            "accuracy": 0.5138,
            "f1": 0.49752122661281784,
            "f1_weighted": 0.49752122661281784
          },
          {
            "accuracy": 0.506,
            "f1": 0.48766400010238636,
            "f1_weighted": 0.4876640001023863
          },
          {
            "accuracy": 0.5086,
            "f1": 0.4942522253026089,
            "f1_weighted": 0.494252225302609
          },
          {
            "accuracy": 0.5218,
            "f1": 0.5158922480304465,
            "f1_weighted": 0.5158922480304465
          },
          {
            "accuracy": 0.516,
            "f1": 0.4883915754804917,
            "f1_weighted": 0.4883915754804917
          },
          {
            "accuracy": 0.5216,
            "f1": 0.5126095852003429,
            "f1_weighted": 0.512609585200343
          },
          {
            "accuracy": 0.4936,
            "f1": 0.4870162734779351,
            "f1_weighted": 0.4870162734779351
          },
          {
            "accuracy": 0.5344,
            "f1": 0.5278103623443443,
            "f1_weighted": 0.5278103623443443
          },
          {
            "accuracy": 0.511,
            "f1": 0.48793155603955063,
            "f1_weighted": 0.4879315560395506
          },
          {
            "accuracy": 0.486,
            "f1": 0.45823794470833057,
            "f1_weighted": 0.45823794470833057
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5084199999999999,
        "f1": 0.49387794418676806,
        "f1_weighted": 0.49387794418676806,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5084199999999999,
        "scores_per_experiment": [
          {
            "accuracy": 0.5054,
            "f1": 0.4931280736073669,
            "f1_weighted": 0.493128073607367
          },
          {
            "accuracy": 0.5042,
            "f1": 0.48699869334629203,
            "f1_weighted": 0.48699869334629203
          },
          {
            "accuracy": 0.5122,
            "f1": 0.49887745079314316,
            "f1_weighted": 0.49887745079314316
          },
          {
            "accuracy": 0.5202,
            "f1": 0.5155107195774107,
            "f1_weighted": 0.5155107195774107
          },
          {
            "accuracy": 0.4978,
            "f1": 0.46980323299133786,
            "f1_weighted": 0.46980323299133797
          },
          {
            "accuracy": 0.5254,
            "f1": 0.5177707187301356,
            "f1_weighted": 0.5177707187301356
          },
          {
            "accuracy": 0.4928,
            "f1": 0.4857591535948633,
            "f1_weighted": 0.4857591535948633
          },
          {
            "accuracy": 0.5284,
            "f1": 0.5219180132211879,
            "f1_weighted": 0.5219180132211879
          },
          {
            "accuracy": 0.5098,
            "f1": 0.48749190950338483,
            "f1_weighted": 0.4874919095033848
          },
          {
            "accuracy": 0.488,
            "f1": 0.4615214765025576,
            "f1_weighted": 0.46152147650255765
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}