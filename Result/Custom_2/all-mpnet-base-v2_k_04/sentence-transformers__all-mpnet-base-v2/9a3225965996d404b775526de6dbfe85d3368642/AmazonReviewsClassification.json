{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 66.78212785720825,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.31414,
        "f1": 0.30735107061104217,
        "f1_weighted": 0.30735107061104217,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31414,
        "scores_per_experiment": [
          {
            "accuracy": 0.3274,
            "f1": 0.32308574328743667,
            "f1_weighted": 0.32308574328743667
          },
          {
            "accuracy": 0.3448,
            "f1": 0.3368846780442679,
            "f1_weighted": 0.3368846780442679
          },
          {
            "accuracy": 0.3092,
            "f1": 0.2970500714075811,
            "f1_weighted": 0.29705007140758105
          },
          {
            "accuracy": 0.3158,
            "f1": 0.3147434982984546,
            "f1_weighted": 0.31474349829845466
          },
          {
            "accuracy": 0.3134,
            "f1": 0.3009066796474099,
            "f1_weighted": 0.30090667964740997
          },
          {
            "accuracy": 0.3146,
            "f1": 0.3071263558354161,
            "f1_weighted": 0.30712635583541603
          },
          {
            "accuracy": 0.2866,
            "f1": 0.2846850181389749,
            "f1_weighted": 0.2846850181389749
          },
          {
            "accuracy": 0.3126,
            "f1": 0.3109516700881393,
            "f1_weighted": 0.3109516700881393
          },
          {
            "accuracy": 0.287,
            "f1": 0.28105436653218324,
            "f1_weighted": 0.2810543665321832
          },
          {
            "accuracy": 0.33,
            "f1": 0.3170226248305575,
            "f1_weighted": 0.3170226248305575
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30973999999999996,
        "f1": 0.3038175283059048,
        "f1_weighted": 0.3038175283059048,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30973999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.323,
            "f1": 0.3234621319807926,
            "f1_weighted": 0.32346213198079266
          },
          {
            "accuracy": 0.345,
            "f1": 0.33580652136018113,
            "f1_weighted": 0.3358065213601811
          },
          {
            "accuracy": 0.3072,
            "f1": 0.2973960964749623,
            "f1_weighted": 0.2973960964749623
          },
          {
            "accuracy": 0.3002,
            "f1": 0.29894875287261835,
            "f1_weighted": 0.29894875287261835
          },
          {
            "accuracy": 0.3014,
            "f1": 0.29078763352304177,
            "f1_weighted": 0.29078763352304177
          },
          {
            "accuracy": 0.3206,
            "f1": 0.313997823034744,
            "f1_weighted": 0.31399782303474405
          },
          {
            "accuracy": 0.295,
            "f1": 0.2948422110474017,
            "f1_weighted": 0.2948422110474017
          },
          {
            "accuracy": 0.302,
            "f1": 0.29942555075172816,
            "f1_weighted": 0.29942555075172816
          },
          {
            "accuracy": 0.2906,
            "f1": 0.2839268322555562,
            "f1_weighted": 0.2839268322555562
          },
          {
            "accuracy": 0.3124,
            "f1": 0.2995817297580217,
            "f1_weighted": 0.29958172975802166
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}