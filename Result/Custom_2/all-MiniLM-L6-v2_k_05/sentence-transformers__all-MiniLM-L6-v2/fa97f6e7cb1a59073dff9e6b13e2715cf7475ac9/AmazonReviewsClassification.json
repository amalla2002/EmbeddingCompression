{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 26.973119497299194,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.29922,
        "f1": 0.2934646696009204,
        "f1_weighted": 0.2934646696009204,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.29922,
        "scores_per_experiment": [
          {
            "accuracy": 0.3116,
            "f1": 0.31299791673992694,
            "f1_weighted": 0.312997916739927
          },
          {
            "accuracy": 0.3262,
            "f1": 0.3163565671138571,
            "f1_weighted": 0.3163565671138571
          },
          {
            "accuracy": 0.3084,
            "f1": 0.2999378427435676,
            "f1_weighted": 0.2999378427435676
          },
          {
            "accuracy": 0.2912,
            "f1": 0.291979582347072,
            "f1_weighted": 0.29197958234707205
          },
          {
            "accuracy": 0.3148,
            "f1": 0.3040966228695346,
            "f1_weighted": 0.3040966228695346
          },
          {
            "accuracy": 0.3042,
            "f1": 0.2997387530433825,
            "f1_weighted": 0.2997387530433825
          },
          {
            "accuracy": 0.279,
            "f1": 0.2776299060321906,
            "f1_weighted": 0.2776299060321906
          },
          {
            "accuracy": 0.2894,
            "f1": 0.2892723299534262,
            "f1_weighted": 0.2892723299534263
          },
          {
            "accuracy": 0.2722,
            "f1": 0.2593223411046501,
            "f1_weighted": 0.2593223411046501
          },
          {
            "accuracy": 0.2952,
            "f1": 0.2833148340615963,
            "f1_weighted": 0.2833148340615963
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.29404,
        "f1": 0.2885423436552324,
        "f1_weighted": 0.2885423436552324,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.29404,
        "scores_per_experiment": [
          {
            "accuracy": 0.2944,
            "f1": 0.29371522984853915,
            "f1_weighted": 0.29371522984853915
          },
          {
            "accuracy": 0.3228,
            "f1": 0.3131212611915405,
            "f1_weighted": 0.31312126119154043
          },
          {
            "accuracy": 0.3122,
            "f1": 0.3056997060224548,
            "f1_weighted": 0.3056997060224548
          },
          {
            "accuracy": 0.283,
            "f1": 0.28295320333887763,
            "f1_weighted": 0.28295320333887763
          },
          {
            "accuracy": 0.301,
            "f1": 0.29141644334969996,
            "f1_weighted": 0.29141644334969996
          },
          {
            "accuracy": 0.305,
            "f1": 0.3015127419048974,
            "f1_weighted": 0.30151274190489746
          },
          {
            "accuracy": 0.2672,
            "f1": 0.2654852672295597,
            "f1_weighted": 0.2654852672295597
          },
          {
            "accuracy": 0.2722,
            "f1": 0.27253011545513606,
            "f1_weighted": 0.2725301154551361
          },
          {
            "accuracy": 0.2778,
            "f1": 0.2640914009015814,
            "f1_weighted": 0.26409140090158134
          },
          {
            "accuracy": 0.3048,
            "f1": 0.29489806731003754,
            "f1_weighted": 0.29489806731003754
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}