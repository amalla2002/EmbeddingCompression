{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 27.236806631088257,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.30902,
        "f1": 0.3047383821559909,
        "f1_weighted": 0.3047383821559909,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30902,
        "scores_per_experiment": [
          {
            "accuracy": 0.3214,
            "f1": 0.32223740999132644,
            "f1_weighted": 0.32223740999132644
          },
          {
            "accuracy": 0.3434,
            "f1": 0.33581432837056574,
            "f1_weighted": 0.3358143283705658
          },
          {
            "accuracy": 0.3182,
            "f1": 0.3121845540588304,
            "f1_weighted": 0.31218455405883044
          },
          {
            "accuracy": 0.3022,
            "f1": 0.3037632407445101,
            "f1_weighted": 0.30376324074451017
          },
          {
            "accuracy": 0.3208,
            "f1": 0.3137517859991613,
            "f1_weighted": 0.31375178599916126
          },
          {
            "accuracy": 0.3184,
            "f1": 0.3147355298156368,
            "f1_weighted": 0.3147355298156368
          },
          {
            "accuracy": 0.2772,
            "f1": 0.2761601622460376,
            "f1_weighted": 0.2761601622460376
          },
          {
            "accuracy": 0.3032,
            "f1": 0.3030773403212792,
            "f1_weighted": 0.3030773403212792
          },
          {
            "accuracy": 0.2822,
            "f1": 0.27210473171287525,
            "f1_weighted": 0.2721047317128753
          },
          {
            "accuracy": 0.3032,
            "f1": 0.29355473829968626,
            "f1_weighted": 0.29355473829968626
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30204000000000003,
        "f1": 0.29811065391877656,
        "f1_weighted": 0.2981106539187766,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30204000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.2992,
            "f1": 0.3007282459868491,
            "f1_weighted": 0.3007282459868491
          },
          {
            "accuracy": 0.3392,
            "f1": 0.33150271370865714,
            "f1_weighted": 0.3315027137086571
          },
          {
            "accuracy": 0.3116,
            "f1": 0.3070723612759926,
            "f1_weighted": 0.3070723612759925
          },
          {
            "accuracy": 0.2908,
            "f1": 0.2922402437860921,
            "f1_weighted": 0.29224024378609204
          },
          {
            "accuracy": 0.3098,
            "f1": 0.3021093247523523,
            "f1_weighted": 0.3021093247523523
          },
          {
            "accuracy": 0.323,
            "f1": 0.3189820814779126,
            "f1_weighted": 0.3189820814779126
          },
          {
            "accuracy": 0.2746,
            "f1": 0.273649972788427,
            "f1_weighted": 0.273649972788427
          },
          {
            "accuracy": 0.278,
            "f1": 0.2784582269163229,
            "f1_weighted": 0.2784582269163229
          },
          {
            "accuracy": 0.2856,
            "f1": 0.27617585380252313,
            "f1_weighted": 0.27617585380252313
          },
          {
            "accuracy": 0.3086,
            "f1": 0.3001875146926369,
            "f1_weighted": 0.30018751469263694
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}