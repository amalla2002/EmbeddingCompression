{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 30.375370979309082,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.30604,
        "f1": 0.30085276733324384,
        "f1_weighted": 0.30085276733324384,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30604,
        "scores_per_experiment": [
          {
            "accuracy": 0.3224,
            "f1": 0.3231599917273319,
            "f1_weighted": 0.32315999172733184
          },
          {
            "accuracy": 0.337,
            "f1": 0.3264587879029889,
            "f1_weighted": 0.32645878790298893
          },
          {
            "accuracy": 0.3112,
            "f1": 0.30619013627864955,
            "f1_weighted": 0.3061901362786495
          },
          {
            "accuracy": 0.3024,
            "f1": 0.3036466325953073,
            "f1_weighted": 0.3036466325953073
          },
          {
            "accuracy": 0.322,
            "f1": 0.31287568008286665,
            "f1_weighted": 0.31287568008286665
          },
          {
            "accuracy": 0.318,
            "f1": 0.31401986513202473,
            "f1_weighted": 0.3140198651320247
          },
          {
            "accuracy": 0.276,
            "f1": 0.27482610120656803,
            "f1_weighted": 0.27482610120656803
          },
          {
            "accuracy": 0.2948,
            "f1": 0.2952544604977613,
            "f1_weighted": 0.2952544604977612
          },
          {
            "accuracy": 0.2754,
            "f1": 0.2633961320663135,
            "f1_weighted": 0.26339613206631357
          },
          {
            "accuracy": 0.3012,
            "f1": 0.2886998858426268,
            "f1_weighted": 0.28869988584262685
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30056,
        "f1": 0.29525811742777874,
        "f1_weighted": 0.29525811742777874,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30056,
        "scores_per_experiment": [
          {
            "accuracy": 0.3026,
            "f1": 0.30179360968604857,
            "f1_weighted": 0.3017936096860485
          },
          {
            "accuracy": 0.3358,
            "f1": 0.3252033983690323,
            "f1_weighted": 0.3252033983690323
          },
          {
            "accuracy": 0.3138,
            "f1": 0.30895320873352417,
            "f1_weighted": 0.3089532087335241
          },
          {
            "accuracy": 0.2948,
            "f1": 0.29590765113623274,
            "f1_weighted": 0.29590765113623274
          },
          {
            "accuracy": 0.31,
            "f1": 0.3008126615558366,
            "f1_weighted": 0.3008126615558367
          },
          {
            "accuracy": 0.3214,
            "f1": 0.31708076750224945,
            "f1_weighted": 0.31708076750224945
          },
          {
            "accuracy": 0.2664,
            "f1": 0.26465437468019903,
            "f1_weighted": 0.264654374680199
          },
          {
            "accuracy": 0.272,
            "f1": 0.27246689127776663,
            "f1_weighted": 0.2724668912777666
          },
          {
            "accuracy": 0.2822,
            "f1": 0.2705016071288611,
            "f1_weighted": 0.27050160712886107
          },
          {
            "accuracy": 0.3066,
            "f1": 0.29520700420803675,
            "f1_weighted": 0.29520700420803675
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}