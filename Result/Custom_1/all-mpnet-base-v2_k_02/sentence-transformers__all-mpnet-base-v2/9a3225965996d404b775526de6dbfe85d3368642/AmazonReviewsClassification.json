{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 113.43578052520752,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.31262,
        "f1": 0.30753452893136185,
        "f1_weighted": 0.30753452893136185,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31262,
        "scores_per_experiment": [
          {
            "accuracy": 0.327,
            "f1": 0.3256007395676549,
            "f1_weighted": 0.32560073956765484
          },
          {
            "accuracy": 0.3382,
            "f1": 0.33085867856176404,
            "f1_weighted": 0.330858678561764
          },
          {
            "accuracy": 0.3024,
            "f1": 0.29755581171948986,
            "f1_weighted": 0.29755581171948986
          },
          {
            "accuracy": 0.319,
            "f1": 0.31992955486261865,
            "f1_weighted": 0.31992955486261865
          },
          {
            "accuracy": 0.3052,
            "f1": 0.2947093783049172,
            "f1_weighted": 0.2947093783049172
          },
          {
            "accuracy": 0.3124,
            "f1": 0.3043774352467327,
            "f1_weighted": 0.3043774352467328
          },
          {
            "accuracy": 0.2848,
            "f1": 0.2844815126603055,
            "f1_weighted": 0.2844815126603055
          },
          {
            "accuracy": 0.3146,
            "f1": 0.3137760398158099,
            "f1_weighted": 0.31377603981580987
          },
          {
            "accuracy": 0.2918,
            "f1": 0.28555490365548264,
            "f1_weighted": 0.28555490365548264
          },
          {
            "accuracy": 0.3308,
            "f1": 0.31850123491884286,
            "f1_weighted": 0.31850123491884286
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30856,
        "f1": 0.3043290782574479,
        "f1_weighted": 0.3043290782574479,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30856,
        "scores_per_experiment": [
          {
            "accuracy": 0.322,
            "f1": 0.32406224881758794,
            "f1_weighted": 0.3240622488175879
          },
          {
            "accuracy": 0.3414,
            "f1": 0.3326229066784594,
            "f1_weighted": 0.33262290667845934
          },
          {
            "accuracy": 0.3014,
            "f1": 0.29905938042945623,
            "f1_weighted": 0.2990593804294563
          },
          {
            "accuracy": 0.3054,
            "f1": 0.306191269318308,
            "f1_weighted": 0.30619126931830803
          },
          {
            "accuracy": 0.3006,
            "f1": 0.2913664757253719,
            "f1_weighted": 0.29136647572537183
          },
          {
            "accuracy": 0.3158,
            "f1": 0.3082818056539877,
            "f1_weighted": 0.3082818056539878
          },
          {
            "accuracy": 0.2862,
            "f1": 0.28755910943600915,
            "f1_weighted": 0.2875591094360092
          },
          {
            "accuracy": 0.3062,
            "f1": 0.30497950028299814,
            "f1_weighted": 0.3049795002829981
          },
          {
            "accuracy": 0.2952,
            "f1": 0.2898351616732077,
            "f1_weighted": 0.28983516167320766
          },
          {
            "accuracy": 0.3114,
            "f1": 0.2993329245590931,
            "f1_weighted": 0.29933292455909305
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}