{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 1718.362428188324,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.31462,
        "f1": 0.30824733066146076,
        "f1_weighted": 0.30824733066146076,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31462,
        "scores_per_experiment": [
          {
            "accuracy": 0.327,
            "f1": 0.32525528561437544,
            "f1_weighted": 0.32525528561437556
          },
          {
            "accuracy": 0.3392,
            "f1": 0.33026002640886365,
            "f1_weighted": 0.33026002640886365
          },
          {
            "accuracy": 0.3066,
            "f1": 0.2990501650684937,
            "f1_weighted": 0.2990501650684937
          },
          {
            "accuracy": 0.3184,
            "f1": 0.31997382703389515,
            "f1_weighted": 0.3199738270338952
          },
          {
            "accuracy": 0.3116,
            "f1": 0.2990453670933907,
            "f1_weighted": 0.29904536709339075
          },
          {
            "accuracy": 0.3204,
            "f1": 0.3097419998819725,
            "f1_weighted": 0.30974199988197254
          },
          {
            "accuracy": 0.2884,
            "f1": 0.286900692062379,
            "f1_weighted": 0.28690069206237906
          },
          {
            "accuracy": 0.3156,
            "f1": 0.31352594838186565,
            "f1_weighted": 0.3135259483818656
          },
          {
            "accuracy": 0.289,
            "f1": 0.2823133749728795,
            "f1_weighted": 0.28231337497287956
          },
          {
            "accuracy": 0.33,
            "f1": 0.31640662009649234,
            "f1_weighted": 0.31640662009649234
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.31038,
        "f1": 0.3049967397512003,
        "f1_weighted": 0.3049967397512003,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31038,
        "scores_per_experiment": [
          {
            "accuracy": 0.3178,
            "f1": 0.31913597917032127,
            "f1_weighted": 0.31913597917032127
          },
          {
            "accuracy": 0.3426,
            "f1": 0.33383941209386947,
            "f1_weighted": 0.33383941209386947
          },
          {
            "accuracy": 0.307,
            "f1": 0.30193022772753075,
            "f1_weighted": 0.30193022772753075
          },
          {
            "accuracy": 0.3104,
            "f1": 0.31181756810828704,
            "f1_weighted": 0.31181756810828704
          },
          {
            "accuracy": 0.3056,
            "f1": 0.2946128586999499,
            "f1_weighted": 0.2946128586999499
          },
          {
            "accuracy": 0.3222,
            "f1": 0.31199077093758665,
            "f1_weighted": 0.31199077093758665
          },
          {
            "accuracy": 0.2856,
            "f1": 0.28594698746758396,
            "f1_weighted": 0.28594698746758396
          },
          {
            "accuracy": 0.3034,
            "f1": 0.3006944639624642,
            "f1_weighted": 0.30069446396246424
          },
          {
            "accuracy": 0.2952,
            "f1": 0.2895517405678612,
            "f1_weighted": 0.2895517405678612
          },
          {
            "accuracy": 0.314,
            "f1": 0.30044738877654903,
            "f1_weighted": 0.300447388776549
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}