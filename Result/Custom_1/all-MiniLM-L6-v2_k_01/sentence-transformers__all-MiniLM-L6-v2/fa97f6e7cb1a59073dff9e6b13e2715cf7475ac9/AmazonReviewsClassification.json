{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 30.415995836257935,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.30618,
        "f1": 0.30200581930779674,
        "f1_weighted": 0.30200581930779685,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30618,
        "scores_per_experiment": [
          {
            "accuracy": 0.3156,
            "f1": 0.3138656573454851,
            "f1_weighted": 0.3138656573454851
          },
          {
            "accuracy": 0.3432,
            "f1": 0.33600085016569914,
            "f1_weighted": 0.3360008501656992
          },
          {
            "accuracy": 0.3172,
            "f1": 0.3126823017218985,
            "f1_weighted": 0.31268230172189854
          },
          {
            "accuracy": 0.2974,
            "f1": 0.2984288890079575,
            "f1_weighted": 0.2984288890079575
          },
          {
            "accuracy": 0.3168,
            "f1": 0.30937256492200854,
            "f1_weighted": 0.30937256492200854
          },
          {
            "accuracy": 0.3212,
            "f1": 0.3159928583801421,
            "f1_weighted": 0.3159928583801421
          },
          {
            "accuracy": 0.2692,
            "f1": 0.26901110143010415,
            "f1_weighted": 0.2690111014301042
          },
          {
            "accuracy": 0.2984,
            "f1": 0.2984662277054283,
            "f1_weighted": 0.29846622770542836
          },
          {
            "accuracy": 0.2838,
            "f1": 0.2760830798847425,
            "f1_weighted": 0.2760830798847425
          },
          {
            "accuracy": 0.299,
            "f1": 0.29015466251450195,
            "f1_weighted": 0.290154662514502
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30296,
        "f1": 0.29983044183210267,
        "f1_weighted": 0.29983044183210267,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30296,
        "scores_per_experiment": [
          {
            "accuracy": 0.3038,
            "f1": 0.3062560933141755,
            "f1_weighted": 0.3062560933141755
          },
          {
            "accuracy": 0.3426,
            "f1": 0.33507945287840685,
            "f1_weighted": 0.3350794528784068
          },
          {
            "accuracy": 0.3162,
            "f1": 0.3127207327479824,
            "f1_weighted": 0.31272073274798234
          },
          {
            "accuracy": 0.2932,
            "f1": 0.2944894271953314,
            "f1_weighted": 0.29448942719533133
          },
          {
            "accuracy": 0.307,
            "f1": 0.2999863704868187,
            "f1_weighted": 0.29998637048681864
          },
          {
            "accuracy": 0.3254,
            "f1": 0.32072740773817193,
            "f1_weighted": 0.32072740773817193
          },
          {
            "accuracy": 0.2706,
            "f1": 0.27074549459860886,
            "f1_weighted": 0.2707454945986088
          },
          {
            "accuracy": 0.2818,
            "f1": 0.2828856072786448,
            "f1_weighted": 0.28288560727864476
          },
          {
            "accuracy": 0.2896,
            "f1": 0.28326553428592166,
            "f1_weighted": 0.2832655342859217
          },
          {
            "accuracy": 0.2994,
            "f1": 0.2921482977969647,
            "f1_weighted": 0.2921482977969647
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}