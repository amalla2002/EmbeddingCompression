{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 189.87284421920776,
  "kg_co2_emissions": null,
  "mteb_version": "1.15.2",
  "scores": {
    "test": [
      {
        "accuracy": 0.51142,
        "f1": 0.4966719814419555,
        "f1_weighted": 0.4966719814419555,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.51142,
        "scores_per_experiment": [
          {
            "accuracy": 0.5196,
            "f1": 0.5017295695757058,
            "f1_weighted": 0.5017295695757059
          },
          {
            "accuracy": 0.5068,
            "f1": 0.49054289830412595,
            "f1_weighted": 0.4905428983041259
          },
          {
            "accuracy": 0.5106,
            "f1": 0.5007756953490395,
            "f1_weighted": 0.5007756953490397
          },
          {
            "accuracy": 0.5184,
            "f1": 0.5136805195859687,
            "f1_weighted": 0.5136805195859688
          },
          {
            "accuracy": 0.519,
            "f1": 0.4897526591964662,
            "f1_weighted": 0.48975265919646616
          },
          {
            "accuracy": 0.5246,
            "f1": 0.513546965158237,
            "f1_weighted": 0.513546965158237
          },
          {
            "accuracy": 0.4956,
            "f1": 0.489629132378696,
            "f1_weighted": 0.489629132378696
          },
          {
            "accuracy": 0.5346,
            "f1": 0.5288280603873764,
            "f1_weighted": 0.5288280603873764
          },
          {
            "accuracy": 0.5034,
            "f1": 0.48500285362010753,
            "f1_weighted": 0.48500285362010764
          },
          {
            "accuracy": 0.4816,
            "f1": 0.45323146086383226,
            "f1_weighted": 0.4532314608638323
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.50946,
        "f1": 0.49505940081207467,
        "f1_weighted": 0.49505940081207467,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.50946,
        "scores_per_experiment": [
          {
            "accuracy": 0.5142,
            "f1": 0.49996380651837014,
            "f1_weighted": 0.4999638065183701
          },
          {
            "accuracy": 0.5038,
            "f1": 0.4870827840708275,
            "f1_weighted": 0.4870827840708275
          },
          {
            "accuracy": 0.5058,
            "f1": 0.49845479474332144,
            "f1_weighted": 0.4984547947433215
          },
          {
            "accuracy": 0.5198,
            "f1": 0.5158790742333851,
            "f1_weighted": 0.5158790742333852
          },
          {
            "accuracy": 0.503,
            "f1": 0.47078441682842237,
            "f1_weighted": 0.4707844168284223
          },
          {
            "accuracy": 0.5308,
            "f1": 0.5194245674953303,
            "f1_weighted": 0.5194245674953303
          },
          {
            "accuracy": 0.4906,
            "f1": 0.48297003728748356,
            "f1_weighted": 0.48297003728748367
          },
          {
            "accuracy": 0.5334,
            "f1": 0.5283890399478509,
            "f1_weighted": 0.5283890399478509
          },
          {
            "accuracy": 0.5088,
            "f1": 0.4887023240791722,
            "f1_weighted": 0.4887023240791723
          },
          {
            "accuracy": 0.4844,
            "f1": 0.4589431629165824,
            "f1_weighted": 0.45894316291658244
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}